# llm_output_evaluation
Individual assessment scripts for various outputs of LLM use cases

Developed within the PySpark framework - it may be advisable to add a timeout clause to some scripts with long-running functions

Assessment technique and scripts are geared toward Task Based LLM agents/output
